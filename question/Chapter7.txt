# 第7章　ランダムフォレスト
1. 全く同じ訓練データを使って5個のモデルを訓練し、それらがすべての95％の適合率を達成したとき、それらのモデルを組み合わせたら、もっと良い結果が得られる可能性はあるか。もし、そうだとすれば、どのようにして組み合わせればよいか。

- ある。ソフト投票にして多数決にすればよい。

2. ハード投票分類器とソフト投票分類器の違いは何か。

- ハード投票分類器は、そのモデルが一番確率が高いと思ったものに投票するのに対し、ソフト投票分類器は確率で比例配分して投票する。

3. 複数のサーバーで分散処理することによって、バギングアンサンブルのスピードを上げることはできるか。ペースティングアンサンブル、ブースティングアンサンブル、ランダムフォレスト、スタッキングアンサンブルではどうか。

- 分からない……。
- (解答)バギングアンサンブルに含まれる個々の予測器は互いに独立しているため、バギングアンサンブルの訓練は、複数のサーバーで分散処理すればスピードは上がる。ペースティングアンサンブルやランダムフォレストも同様。ブースティングアンサンブルは、個々の予測器は、前の予測器を基礎として作られており逐次的な訓練が必要なため、分散処理をすることはできない。スタッキングアンサンブルの場合、個々の層の予測器はどれも互いに独立しているので、並列処理をすることは可能。が、層をまたぐ並列処理はできない。

4. OOB検証の長所は何か。

- 検証データセットを作る必要がない。

5. Extra-Trees分類器が通常のランダムフォレストよりも無作為的なのは、何によるものか。この余分に無作為的なことにはどのような意味があるか。Extra-Treeは、通常のランダムフォレストに比べて遅いか、速いか。

- いくつかの特徴量を完全に無視する。過学習を防ぐ効果がある。速い。
- (解答)Extra-Treesは、木を育てるときに、個々の特徴量で可能な限り最良の閾値を探すのではなく、無作為な閾値を使う。よって訓練はランダムフォレストは速い。

6. 手元のアダブーストアンサンブルが訓練データに過小適合している場合、どのハイパーパラメタをどのように操作すべきか。

- 分からない……。
- (解答)推定器を増やすか、ベースの推定器の正則化パラメタを下げる。学習率を少し上げる。

7. 勾配ブースティングアンサンブルが訓練データに過学習している場合、学習率を上げるべきか下げるべきか。

- 下げるべき。

8. 省略
9. 省略